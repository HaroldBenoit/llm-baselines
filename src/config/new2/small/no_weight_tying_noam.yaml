model: "noam"
weight_tying: False

compile: True
grad_clip: 1.0
save_checkpoint_freq: 500
wandb_project: "lauzhack-llm"
wandb_group: "new2"
wandb: True
n_layer: 10
opt: "adamw"
weight_decay: 0.1
lr: 1.e-3
#rho: 0.05
run_prefix: "no_weight_tying_small"


iterations: 13000  ## train itr: 867 ms, 3 hours of training => num iterations = (1/0.867)*3*60*60 = 12456
batch_size: 64
acc_steps: 4
